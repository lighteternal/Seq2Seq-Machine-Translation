{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to load trained model and perform translations\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    "from allennlp.modules.attention import DotProductAttention\n",
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.predictors import SimpleSeq2SeqPredictor\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "EN_EMBEDDING_DIM = 256\n",
    "ZH_EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "\n",
    "CUDA_DEVICE = 0\n",
    "\n",
    "#Loading the reader, vocab, embeddings and model structure \n",
    "reader = Seq2SeqDatasetReader(\n",
    "    source_tokenizer=WordTokenizer(),\n",
    "    target_tokenizer=CharacterTokenizer(),\n",
    "    source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
    "    target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')},\n",
    "    lazy = True)\n",
    "\n",
    "vocab = Vocabulary.from_files(\"/home/infili/translation/Translation/trained/20200119/vocabulary_films_ana7_20200119/\")\n",
    "\n",
    "\n",
    "en_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                         embedding_dim=EN_EMBEDDING_DIM)\n",
    "\n",
    "encoder = StackedSelfAttentionEncoder(input_dim=EN_EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, projection_dim=128, feedforward_hidden_dim=128, num_layers=1, num_attention_heads=8)\n",
    "\n",
    "source_embedder = BasicTextFieldEmbedder({\"tokens\": en_embedding})\n",
    "\n",
    "attention = DotProductAttention()\n",
    "\n",
    "max_decoding_steps = 300  \n",
    "model_pred = SimpleSeq2Seq(vocab, source_embedder, encoder, max_decoding_steps,\n",
    "                      target_embedding_dim=ZH_EMBEDDING_DIM,\n",
    "                      target_namespace='target_tokens',\n",
    "                      attention=attention,\n",
    "                      beam_size=8,\n",
    "                      use_bleu=True)\n",
    "\n",
    "# Reload the trained model.\n",
    "with open(\"/home/infili/translation/Translation/trained/20200119/model_greek_films_ana7_20200119.th\", 'rb') as f:\n",
    "    model_pred.load_state_dict(torch.load(f))\n",
    "    model_pred.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Καλημέρα! ['good morning!']\n",
      "Πόσο χρόνο έχουμε μέχρι το επόμενο διάλειμμα; ['how long have we have the next break?']\n",
      "Αυτή είναι μια καλή προσπάθεια για μετάφραση ['this is a good try to translate.']\n",
      "Ίσως θα μπορούσε να είναι καλύτερη. ['maybe he could be better.']\n",
      "Αλλά με τόσο λίγα δεδομένα, δεν περίμενα και πολλά. ['but with so few data, i didn't expect a lot.']\n",
      "Θα δω αν μπορώ να αυξήσω το σύνολο εκπαίδευσης ['i'll see if i can raise the training.']\n",
      "Εντωμεταξύ, ας δοκιμάσουμε μερικά παραδείγματα ['meanwhile, let's try some examples.']\n",
      "Άλλωστε αυτό κάνουμε τόση ώρα, σωστά; ['besides, what about this, right?']\n",
      "Ας ξεκινήσουμε με τα βασικά: ['let's start with the basic,']\n",
      "Ναι, αυτό θα μπορούσαμε να το κάνουμε ['yeah, that we could do it.']\n",
      "Πως σε λένε; ['what's your name?']\n",
      "Μπορώ να κάνω κάτι για σένα; ['can i do something for you?']\n",
      "Και τώρα κάτι πιο δύσκολο: ['and now something hard:']\n",
      "Μου την έφερες! ['you brought me!']\n",
      "Νιώθω πως κάτι περίεργο συμβαίνει. ['i feel something weird.']\n",
      "Πεινάω από τη στιγμή που ξύπνησα ['i'm hungry from the moment i woke up.']\n",
      "Θα βγω έξω μια βολτα στο δάσος ['i'm going out a ride in the woods.']\n",
      "Επιστρέφω σε 10 λεπτά. ['i'll be back in 10 minutes.']\n",
      "Γύρισα από το σχολείο κι έπεσα για ύπνο αμέσως. ['i came back from school and i went to bed immediately.']\n",
      "Θα πάμε διακοπές στο Παρίσι! ['we'll go to paris!']\n",
      "Είμαι λίγο αγχωμένος για τις εξετάσεις... ['i'm a little nervous about tests...']\n",
      "Φυσικά και ο φίλος σου μπορεί να έρθει! ['of course your friend can come!']\n",
      "Όταν γράφω μεταφορικά, είναι δύσκολο να μεταφράσω σωστά. ['when i'm written to me, it's hard to translate translately.']\n",
      "Είναι ξεκάθαρο ότι μερικές προτάσεις δε βγάζουν νόημα ['it's clear that some sentences don't make sense.']\n",
      "Πάμε και σε μερικές κριτικές: ['let's go to some reviews']\n",
      "Ο χώρος και το φαγητό ήταν τέλεια! ['the room and the food was perfect!']\n",
      "Μου έριξε χυλόπιτα ['she shot me down']\n",
      "Τρελαίνομαι για πουρέ. ['i love mashed potatoes.']\n",
      "Όλα απαίσια, μην κάνετε τον κόπο ['everything awful, don't bother.']\n",
      "Δεν με ενθουσίασε ιδιαίτερα αλλά θα του έδινα μια δεύτερη ευκαιρία. ['i'm not really excited to explain him but i would give him a second chance.']\n",
      "Η Κατερίνα λέει ότι είσαι τέλειο! ['katerina says you're perfect!']\n",
      "Σε έχω ρωτήσει τόσες φορές αν τελικά θα βγούμε και δεν μου έχεις απαντήσει ακόμα. ['i've asked you so many times if we finally go out and you don't have yet.']\n",
      "Ο Γιώργος έχασε το πορτοφόλι του, πήγε στην αστυνομία και το βρήκαν. ['george lost his wallet, he went to the police and they found it.']\n",
      "Αρκετά για σήμερα, τα λέμε αύριο ['enough for today, see you tomorrow.']\n",
      "Είναι μια τέλεια μέρα, είμαστε έτοιμοι για νέες περιπέτειες! ['it's a perfect day, we're ready for new adventures!']\n",
      "Δώσε μου τον κώδικα και θα τον κοιτάξω όταν βρω χρόνο. ['give me the code and i'll look at him when i find time.']\n",
      "Δε θα βάλω οινόπνευμα, τσούζει! ['i won't put on alcohol, it stings!']\n",
      "Σταμάτα να αμφισβητείς τις ικανότητές μου ['stop questioning my skills.']\n",
      "Το φαγητό ήταν πεντανόστιμο και οι τιμές μια χαρουλα.Παρα πολύ τίμιο. ['the food was delicious and prices and very honest.']\n",
      "Είμαι βαθύτατα συγκινημένος. ['i'm deeply touched.']\n",
      "Το παιδί είναι καθυστερημένο. ['the child is retarded.']\n"
     ]
    }
   ],
   "source": [
    "#Predict on new text using loaded model\n",
    "\n",
    "predictor = SimpleSeq2SeqPredictor(model_pred, dataset_reader=reader)\n",
    "\n",
    "\n",
    "#To translate, write comma-separated sentences in quotes:\n",
    "\n",
    "test = [\n",
    "    \"Καλημέρα!\",\n",
    "    \"Πόσο χρόνο έχουμε μέχρι το επόμενο διάλειμμα;\",\n",
    "    \"Αυτή είναι μια καλή προσπάθεια για μετάφραση\",\n",
    "    \"Ίσως θα μπορούσε να είναι καλύτερη.\",\n",
    "    \"Αλλά με τόσο λίγα δεδομένα, δεν περίμενα και πολλά.\",\n",
    "    \"Θα δω αν μπορώ να αυξήσω το σύνολο εκπαίδευσης\",\n",
    "    \"Εντωμεταξύ, ας δοκιμάσουμε μερικά παραδείγματα\",\n",
    "    \"Άλλωστε αυτό κάνουμε τόση ώρα, σωστά;\",\n",
    "    \"Ας ξεκινήσουμε με τα βασικά:\",\n",
    "    \"Ναι, αυτό θα μπορούσαμε να το κάνουμε\",\n",
    "    \"Πως σε λένε;\",\n",
    "    \"Μπορώ να κάνω κάτι για σένα;\",\n",
    "    \"Και τώρα κάτι πιο δύσκολο:\",\n",
    "    \"Μου την έφερες!\",\n",
    "    \"Νιώθω πως κάτι περίεργο συμβαίνει.\",\n",
    "    \"Πεινάω από τη στιγμή που ξύπνησα\",\n",
    "    \"Θα βγω έξω μια βολτα στο δάσος\",\n",
    "    \"Επιστρέφω σε 10 λεπτά.\",\n",
    "    \"Γύρισα από το σχολείο κι έπεσα για ύπνο αμέσως.\",\n",
    "    \"Θα πάμε διακοπές στο Παρίσι!\",\n",
    "    \"Είμαι λίγο αγχωμένος για τις εξετάσεις...\",\n",
    "    \"Φυσικά και ο φίλος σου μπορεί να έρθει!\",\n",
    "    \"Όταν γράφω μεταφορικά, είναι δύσκολο να μεταφράσω σωστά.\",\n",
    "    \"Είναι ξεκάθαρο ότι μερικές προτάσεις δε βγάζουν νόημα\",\n",
    "    \"Πάμε και σε μερικές κριτικές:\",\n",
    "    \"Ο χώρος και το φαγητό ήταν τέλεια!\",\n",
    "    \"Μου έριξε χυλόπιτα\",\n",
    "    \"Τρελαίνομαι για πουρέ.\",\n",
    "    \"Όλα απαίσια, μην κάνετε τον κόπο\",\n",
    "    \"Δεν με ενθουσίασε ιδιαίτερα αλλά θα του έδινα μια δεύτερη ευκαιρία.\",\n",
    "    \"Η Κατερίνα λέει ότι είσαι τέλειο!\",\n",
    "    \"Σε έχω ρωτήσει τόσες φορές αν τελικά θα βγούμε και δεν μου έχεις απαντήσει ακόμα.\",\n",
    "    \"Ο Γιώργος έχασε το πορτοφόλι του, πήγε στην αστυνομία και το βρήκαν.\",\n",
    "    \"Αρκετά για σήμερα, τα λέμε αύριο\",\n",
    "    \"Είναι μια τέλεια μέρα, είμαστε έτοιμοι για νέες περιπέτειες!\",\n",
    "    \"Δώσε μου τον κώδικα και θα τον κοιτάξω όταν βρω χρόνο.\",\n",
    "    \"Δε θα βάλω οινόπνευμα, τσούζει!\",\n",
    "    \"Σταμάτα να αμφισβητείς τις ικανότητές μου\",\n",
    "    \"Το φαγητό ήταν πεντανόστιμο και οι τιμές μια χαρουλα.Παρα πολύ τίμιο.\",\n",
    "    \"Είμαι βαθύτατα συγκινημένος.\",\n",
    "    \"Το παιδί είναι καθυστερημένο.\"\n",
    "]\n",
    "\n",
    "#Parsing the output to remove quotes and irrelevant characters\n",
    "\n",
    "import re\n",
    "regex = r\"', '\"\n",
    "regex2 = r\", \\\"'\\\", '\"\n",
    "subst = \"\"\n",
    "subst2 = \"\"\n",
    "\n",
    "for i in test:\n",
    "    p = predictor.predict(i)['predicted_tokens']\n",
    "    result = re.sub(regex, subst, str(p), 0, re.MULTILINE | re.IGNORECASE)\n",
    "    result = re.sub(regex2, subst2, str(result), 0, re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    print(i,result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
