{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Greek to English test\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    "from allennlp.modules.attention import LinearAttention, BilinearAttention, DotProductAttention\n",
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.predictors import SimpleSeq2SeqPredictor\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "EN_EMBEDDING_DIM = 256\n",
    "ZH_EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "\n",
    "CUDA_DEVICE = 0\n",
    "\n",
    "#def main():\n",
    "reader = Seq2SeqDatasetReader(\n",
    "    source_tokenizer=WordTokenizer(),\n",
    "    target_tokenizer=CharacterTokenizer(),\n",
    "    source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
    "    target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')})\n",
    "train_dataset = reader.read('/home/infili/translation/Translation/corpora/films/el-en-films-cleaned-ana10-cropped.txt')\n",
    "validation_dataset = reader.read('/home/infili/translation/Translation/corpora/films/el-en-films-cleaned-ana10-cropped-dev.txt')\n",
    "\n",
    "\n",
    "vocab = Vocabulary.from_instances(train_dataset + validation_dataset,\n",
    "                                  min_count={'tokens': 3, 'target_tokens': 3})\n",
    "\n",
    "en_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                         embedding_dim=EN_EMBEDDING_DIM)\n",
    "# encoder = PytorchSeq2SeqWrapper(\n",
    "#     torch.nn.LSTM(EN_EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
    "encoder = StackedSelfAttentionEncoder(input_dim=EN_EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, projection_dim=128, feedforward_hidden_dim=128, num_layers=1, num_attention_heads=8)\n",
    "\n",
    "source_embedder = BasicTextFieldEmbedder({\"tokens\": en_embedding})\n",
    "\n",
    "# attention = LinearAttention(HIDDEN_DIM, HIDDEN_DIM, activation=Activation.by_name('tanh')())\n",
    "# attention = BilinearAttention(HIDDEN_DIM, HIDDEN_DIM)\n",
    "attention = DotProductAttention()\n",
    "\n",
    "max_decoding_steps = 50  \n",
    "model = SimpleSeq2Seq(vocab, source_embedder, encoder, max_decoding_steps,\n",
    "                      target_embedding_dim=ZH_EMBEDDING_DIM,\n",
    "                      target_namespace='target_tokens',\n",
    "                      attention=attention,\n",
    "                      beam_size=8,\n",
    "                      use_bleu=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # without this there is no error, but it runs in CPU (instead of GPU). \n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "iterator = BucketIterator(batch_size=32, sorting_keys=[(\"source_tokens\", \"num_tokens\")])\n",
    "\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  patience=20,\n",
    "                  train_dataset=train_dataset,\n",
    "                  validation_dataset=validation_dataset,\n",
    "                  num_epochs=1,\n",
    "                  cuda_device=CUDA_DEVICE)\n",
    "\n",
    "for i in range(50):\n",
    "    print('Epoch: {}'.format(i))\n",
    "    trainer.train()\n",
    "\n",
    "    predictor = SimpleSeq2SeqPredictor(model, reader)\n",
    "\n",
    "    for instance in itertools.islice(validation_dataset, 50):\n",
    "        print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
    "        print('GOLD:', instance.fields['target_tokens'].tokens)\n",
    "        print('PRED:', predictor.predict_instance(instance)['predicted_tokens'])\n",
    "\n",
    "\n",
    "    # Here's how to save the model.\n",
    "with open(\"/home/infili/translation/model_greek_ana10.th\", 'wb') as f:\n",
    "    torch.save(model.state_dict(), f)\n",
    "vocab.save_to_files(\"/home/infili/translation/vocabulary_ana10\")\n",
    "print(\"Model saved. DONE\")\n",
    "#if __name__ == '__main__':\n",
    "#    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Αυτή είναι μια καλή προσπάθεια για μετάφραση ['t', 'h', 'a', 't', \"'\", 's', ' ', 'a', ' ', 'g', 'o', 'o', 'd', ' ', 't', 'r', 'y', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n']\n",
      "Ίσως θα μπορούσε να είναι καλύτερη. ['m', 'a', 'y', 'b', 'e', ' ', 'i', 't', ' ', 'c', 'o', 'u', 'l', 'd', ' ', 'b', 'e', ' ', 'b', 'e', 't', 't', 'e', 'r', '.']\n",
      "Αλλά με τόσο λίγα δεδομένα, δεν περίμενα και πολλά. ['b', 'u', 't', ' ', 's', 'u', 'c', 'h', ' ', 'a', ' ', 'f', 'e', 'w', ' ', 'f', 'a', 'c', 't', 's', ',', ' ', 'i', ' ', 'd', 'i', 'd', 'n', \"'\", 't', ' ', 'e', 'x', 'p', 'e', 'c', 't', ' ', 't', 'o', 'o', ' ', 'm', 'u', 'c', 'h', '.']\n",
      "Θα δω αν μπορώ να αυξήσω το σύνολο εκπαίδευσης ['i', \"'\", 'l', 'l', ' ', 's', 'e', 'e', ' ', 'i', 'f', ' ', 'i', ' ', 'c', 'a', 'n', ' ', 'r', 'a', 'i', 's', 'e', ' ', 'a', ' ', 't', 'r', 'a', 'i', 'n', 'i', 'n', 'g', ' ', 't', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "Εντωμεταξύ, ας δοκιμάσουμε μερικά παραδείγματα ['i', 'n', ' ', 't', 'h', 'e', ' ', 'm', 'e', 'a', 'n', 't', 'i', 'm', 'e', ',', ' ', 'l', 'e', 't', \"'\", 's', ' ', 't', 'r', 'y', ' ', 'a', ' ', 'f', 'e', 'w', ' ', 'e', 'x', 'a', 'm', 'p', 'l', 'e', 's', ' ', 'e', 'x', 'a', 'm', 'p', 'l', 'e', 's']\n",
      "Άλλωστε αυτό κάνουμε τόση ώρα, σωστά; ['b', 'e', 's', 'i', 'd', 'e', 's', ',', ' ', 'w', 'e', \"'\", 'r', 'e', ' ', 'd', 'o', 'i', 'n', 'g', ' ', 'a', 'l', 'l', ' ', 't', 'h', 'i', 's', ' ', 'h', 'o', 'u', 'r', ',', ' ', 'r', 'i', 'g', 'h', 't', '?']\n",
      "Ας ξεκινήσουμε με τα βασικά: ['l', 'e', 't', \"'\", 's', ' ', 's', 't', 'a', 'r', 't', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'e', ' ', 'b', 'a', 's', 'i', 's', ':']\n",
      "Ναι ή όχι; ['y', 'e', 's', ',', ' ', 'o', 'r', ' ', 'n', 'o', 't', '?']\n",
      "Πως σε λένε; ['w', 'h', 'a', 't', \"'\", 's', ' ', 'y', 'o', 'u', 'r', ' ', 'n', 'a', 'm', 'e', '?']\n",
      "Μπορώ να κάνω κάτι για σένα; ['m', 'a', 'y', ' ', 'i', ' ', 'd', 'o', ' ', 's', 'o', 'm', 'e', 't', 'h', 'i', 'n', 'g', ' ', 'f', 'o', 'r', ' ', 'y', 'o', 'u', '?']\n",
      "Και τώρα κάτι πιο δύσκολο: ['a', 'n', 'd', ' ', 'n', 'o', 'w', ' ', 's', 'o', 'm', 'e', 't', 'h', 'i', 'n', 'g', ' ', 'd', 'i', 'r', 'e', 'c', 't', 'i', 'o', 'n', ':']\n",
      "Μου την έφερες! ['y', 'o', 'u', ' ', 'b', 'r', 'o', 'u', 'g', 'h', 't', ' ', 'h', 'e', 'r', '!']\n",
      "Νιώθω πως κάτι περίεργο συμβαίνει. ['i', ' ', 'f', 'e', 'e', 'l', ' ', 's', 'o', 'm', 'e', 't', 'h', 'i', 'n', 'g', ' ', 's', 't', 'r', 'a', 'n', 'g', 'e', ' ', 'i', 'd', 'e', 'a', '.']\n",
      "Πεινάω από τη στιγμή που ξύπνησα ['i', \"'\", 'm', ' ', 'h', 'u', 'n', 'g', 'r', 'y', ' ', 'i', ' ', 'w', 'o', 'k', 'e', ' ', 'u', 'p', '.']\n",
      "Θα βγω έξω μια βολτα στο δάσος ['i', \"'\", 'l', 'l', ' ', 'g', 'o', ' ', 'o', 'u', 't', ' ', 'a', ' ', 'w', 'a', 'l', 'k', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'o', 'd', 's']\n",
      "Επιστρέφω σε 10 λεπτά. ['i', \"'\", 'l', 'l', ' ', 'b', 'e', ' ', 'b', 'a', 'c', 'k', ' ', 'i', 'n', ' ', '1', '0', ' ', 'm', 'i', 'n', 'u', 't', 'e', 's', '.']\n",
      "Γύρισα από το σχολείο κι έπεσα για ύπνο αμέσως. ['i', ' ', 'c', 'a', 'm', 'e', ' ', 'b', 'a', 'c', 'k', ' ', 't', 'o', ' ', 's', 'c', 'h', 'o', 'o', 'l', ' ', 'a', 'n', 'd', ' ', 'i', ' ', 'f', 'e', 'l', 'l', ' ', 'i', 'n', ' ', 'a', 't', ' ', 'o', 'n', 'c', 'e', '.']\n",
      "Θα πάμε διακοπές στο Παρίσι! ['w', 'e', \"'\", 'r', 'e', ' ', 'g', 'o', 'i', 'n', 'g', ' ', 't', 'o', ' ', 'p', 'a', 'r', 'i', 's', '!']\n",
      "Έχω λίγο άγχος για τις εξετάσεις... ['i', \"'\", 'm', ' ', 'a', ' ', 'l', 'i', 't', 't', 'l', 'e', ' ', 'n', 'e', 'r', 'v', 'o', 'u', 's', '.']\n",
      "Φυσικά και ο φίλος σου μπορεί να έρθει! ['o', 'f', ' ', 'c', 'o', 'u', 'r', 's', 'e', ' ', 'y', 'o', 'u', 'r', ' ', 'f', 'r', 'i', 'e', 'n', 'd', ' ', 'c', 'a', 'n', ' ', 'c', 'o', 'm', 'e', '!']\n",
      "Όταν γράφω μεταφορικά, είναι δύσκολο να μεταφράσω σωστά. ['w', 'h', 'e', 'n', ' ', 'i', ' ', 'w', 'r', 'i', 't', 'e', ' ', 't', 'r', 'o', 'u', 'b', 'l', 'e', ',', ' ', 'i', 't', \"'\", 's', ' ', 'h', 'a', 'r', 'd', ' ', 't', 'o', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'e', ' ', 't', 'r', 'o', 'u', 'b']\n",
      "Είναι ξεκάθαρο ότι μερικές προτάσεις δε βγάζουν νόημα ['i', 't', \"'\", 's', ' ', 'c', 'l', 'e', 'a', 'r', ' ', 't', 'h', 'a', 't', ' ', 's', 'o', 'm', 'e', ' ', 's', 'u', 'g', 'g', 'e', 's', 't', 'i', 'o', 'n', 's', ' ', 'd', 'o', 'n', \"'\", 't', ' ', 'e', 'x', 'c', 'u', 's', 'e', ' ', 'm', 'e', '.']\n",
      "Πάμε και σε μερικές κριτικές: ['l', 'e', 't', \"'\", 's', ' ', 'g', 'o', ',', ' ', 'a', 'n', 'd', ' ', 'a', ' ', 'f', 'e', 'w', ' ', 'r', 'e', 'v', 'i', 'e', 'w', 's', ':']\n",
      "Ο χώρος και το φαγητό ήταν τέλεια! ['r', 'o', 'o', 'm', ' ', 'a', 'n', 'd', ' ', 'f', 'o', 'o', 'd', ' ', 'w', 'a', 's', ' ', 'p', 'e', 'r', 'f', 'e', 'c', 't', '!']\n",
      "Μπράβο! Το συστήνω ανεπιφύλακτα ['t', 'h', 'a', 't', ' ', 'i', ' ', 'r', 'e', 'c', 'o', 'm', 'm', 'e', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'r', 'i', 'g', 'h', 't', 'l', 'y', ' ', 'r', 'i', 'g', 'h', 't']\n",
      "Όλα απαίσια, μην κάνετε τον κόπο ['a', 'l', 'l', ' ', 'a', 'w', 'f', 'u', 'l', ',', ' ', 'd', 'o', 'n', \"'\", 't', ' ', 'b', 'o', 't', 'h', 'e', 'r']\n",
      "Δεν με ενθουσίασε αλλά θα του έδινα μια δεύτερη ευκαιρία όμως. ['b', 'u', 't', ' ', 'i', \"'\", 'm', ' ', 'g', 'o', 'n', 'n', 'a', ' ', 'g', 'e', 't', ' ', 'm', 'e', ' ', 'a', ' ', 's', 'e', 'c', 'o', 'n', 'd', ' ', 'c', 'h', 'a', 'n', 'c', 'e', '.']\n",
      "Αυτά για σήμερα, τα λέμε αύριο! ['w', 'e', \"'\", 'l', 'l', ' ', 's', 'e', 'e', ' ', 'y', 'o', 'u', ' ', 't', 'o', 'm', 'o', 'r', 'r', 'o', 'w', '.']\n",
      "Η Κατερίνα λέει ότι είσαι τέλειο! ['c', 'a', 't', 'h', 'e', 'r', 'i', 'n', 'e', ' ', 's', 'a', 'y', 's', ' ', 'y', 'o', 'u', \"'\", 'r', 'e', ' ', 'p', 'e', 'r', 'f', 'e', 'c', 't', '!']\n",
      "Μου αρέσει ο πουρές. ['i', ' ', 'l', 'i', 'k', 'e', ' ', 'p', 'o', 't', 'a', 't', 'o', 'e', 's', '.']\n"
     ]
    }
   ],
   "source": [
    "#Predict using trained model (it has to be loaded)\n",
    "\n",
    "\n",
    "predictor = SimpleSeq2SeqPredictor(model, dataset_reader=reader)\n",
    "\n",
    "\n",
    "test = [\n",
    "    \"Αυτή είναι μια καλή προσπάθεια για μετάφραση\",\n",
    "    \"Ίσως θα μπορούσε να είναι καλύτερη.\",\n",
    "    \"Αλλά με τόσο λίγα δεδομένα, δεν περίμενα και πολλά.\",\n",
    "    \"Θα δω αν μπορώ να αυξήσω το σύνολο εκπαίδευσης\",\n",
    "    \"Εντωμεταξύ, ας δοκιμάσουμε μερικά παραδείγματα\",\n",
    "    \"Άλλωστε αυτό κάνουμε τόση ώρα, σωστά;\",\n",
    "    \"Ας ξεκινήσουμε με τα βασικά:\",\n",
    "    \"Ναι ή όχι;\",\n",
    "    \"Πως σε λένε;\",\n",
    "    \"Μπορώ να κάνω κάτι για σένα;\",\n",
    "    \"Και τώρα κάτι πιο δύσκολο:\",\n",
    "    \"Μου την έφερες!\",\n",
    "    \"Νιώθω πως κάτι περίεργο συμβαίνει.\",\n",
    "    \"Πεινάω από τη στιγμή που ξύπνησα\",\n",
    "    \"Θα βγω έξω μια βολτα στο δάσος\",\n",
    "    \"Επιστρέφω σε 10 λεπτά.\",\n",
    "    \"Γύρισα από το σχολείο κι έπεσα για ύπνο αμέσως.\",\n",
    "    \"Θα πάμε διακοπές στο Παρίσι!\",\n",
    "    \"Έχω λίγο άγχος για τις εξετάσεις...\",\n",
    "    \"Φυσικά και ο φίλος σου μπορεί να έρθει!\",\n",
    "    \"Όταν γράφω μεταφορικά, είναι δύσκολο να μεταφράσω σωστά.\",\n",
    "    \"Είναι ξεκάθαρο ότι μερικές προτάσεις δε βγάζουν νόημα\",\n",
    "    \"Πάμε και σε μερικές κριτικές:\",\n",
    "    \"Ο χώρος και το φαγητό ήταν τέλεια!\",\n",
    "    \"Μπράβο! Το συστήνω ανεπιφύλακτα\",\n",
    "    \"Όλα απαίσια, μην κάνετε τον κόπο\",\n",
    "    \"Δεν με ενθουσίασε αλλά θα του έδινα μια δεύτερη ευκαιρία όμως.\",\n",
    "    \"Αυτά για σήμερα, τα λέμε αύριο!\",\n",
    "    \"Η Κατερίνα λέει ότι είσαι τέλειο!\",\n",
    "    \"Μου αρέσει ο πουρές.\",\n",
    "]\n",
    "\n",
    "\n",
    "for i in test:\n",
    "    p = predictor.predict(i)['predicted_tokens']\n",
    "    print(i,p) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
