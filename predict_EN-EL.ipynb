{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to load trained model and perform translations\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    "from allennlp.modules.attention import DotProductAttention\n",
    "from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.predictors import SimpleSeq2SeqPredictor\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "EN_EMBEDDING_DIM = 256\n",
    "ZH_EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "\n",
    "CUDA_DEVICE = 0\n",
    "\n",
    "#Loading the reader, vocab, embeddings and model structure \n",
    "reader = Seq2SeqDatasetReader(\n",
    "    source_tokenizer=WordTokenizer(),\n",
    "    target_tokenizer=CharacterTokenizer(),\n",
    "    source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
    "    target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')},\n",
    "    lazy = True)\n",
    "\n",
    "vocab = Vocabulary.from_files(\"/home/infili/translation/Translation/trained/20200202/paracrawl_vocabulary_20200202\")\n",
    "\n",
    "\n",
    "en_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                         embedding_dim=EN_EMBEDDING_DIM)\n",
    "\n",
    "encoder = StackedSelfAttentionEncoder(input_dim=EN_EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, projection_dim=128, feedforward_hidden_dim=128, num_layers=1, num_attention_heads=8)\n",
    "\n",
    "source_embedder = BasicTextFieldEmbedder({\"tokens\": en_embedding})\n",
    "\n",
    "attention = DotProductAttention()\n",
    "\n",
    "max_decoding_steps = 300  \n",
    "model_pred = SimpleSeq2Seq(vocab, source_embedder, encoder, max_decoding_steps,\n",
    "                      target_embedding_dim=ZH_EMBEDDING_DIM,\n",
    "                      target_namespace='target_tokens',\n",
    "                      attention=attention,\n",
    "                      beam_size=8,\n",
    "                      use_bleu=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_pred.to(device) # without this there is no error, but it runs in CPU (instead of GPU). \n",
    "\n",
    "\n",
    "# Reload the trained model.\n",
    "with open(\"/home/infili/translation/Translation/trained/20200202/paracrawl_model_20200202.th\", 'rb') as f:\n",
    "    model_pred.load_state_dict(torch.load(f))\n",
    "    model_pred.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on new text using loaded model\n",
    "\n",
    "predictor = SimpleSeq2SeqPredictor(model_pred, dataset_reader=reader)\n",
    "\n",
    "\n",
    "#To translate, write comma-separated sentences in quotes:\n",
    "\n",
    "test = [\n",
    "    \"European Union law is a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states. \",\n",
    "    \"What is European Union Law?\",\n",
    "    \"a body of treaties and legislation\",\n",
    "    \"What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?\",\n",
    "    \"Computational complexity theory\",\n",
    "    \"Consciousness at its simplest form is sentience or awareness of internal or external existence\",\n",
    "    \"She studied medicine but also became an expert of legal matters, by working as lawyer assistant when she was young .\",\n",
    "    \"He was born in 1979 in Prague and was a member of the royal family.\",\n",
    "    \"How are you feeling today?\",\n",
    "    \"As far as I know, the economic crisis doesn't allow for military expenses.\",\n",
    "    \"Yes I will do it\",\n",
    "    \"I am thirsty for knowledge.\",\n",
    "    \"Thousands reports from all over the world have confirmed the incident.\", \n",
    "    \"Three beers and a steak please.\",\n",
    "    \"At least let me pay the bill this time!\",\n",
    "    \"This product meets the requirements set by the clients.\",\n",
    "    \"I do not intend to leave the city anytime soon.\",\n",
    "    \"The socioeconomic problems have hurt the local industry the most.\",\n",
    "    \"The food is really tasty, but the environment needs improvement.\",\n",
    "    \"I would definitely recommend this place for vacation.\",\n",
    "    \"According to Christopher Tolkien, it is no longer possible to trace the exact date of the work's composition. \"\n",
    "]\n",
    "\n",
    "#Parsing the output to remove quotes and irrelevant characters\n",
    "\n",
    "import re\n",
    "regex = r\"', '\"\n",
    "regex2 = r\", \\\"'\\\", '\"\n",
    "subst = \"\"\n",
    "subst2 = \"\"\n",
    "\n",
    "for i in test:\n",
    "    p = predictor.predict(i)['predicted_tokens']\n",
    "    result = re.sub(regex, subst, str(p), 0, re.MULTILINE | re.IGNORECASE)\n",
    "    result = re.sub(regex2, subst2, str(result), 0, re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    print(i,result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             context  \\\n",
      "0  Architecturally, the school has a Catholic cha...   \n",
      "1  Architecturally, the school has a Catholic cha...   \n",
      "2  Architecturally, the school has a Catholic cha...   \n",
      "3  Architecturally, the school has a Catholic cha...   \n",
      "4  Architecturally, the school has a Catholic cha...   \n",
      "\n",
      "                                            question  \\\n",
      "0  To whom did the Virgin Mary allegedly appear i...   \n",
      "1  What is in front of the Notre Dame Main Building?   \n",
      "2  The Basilica of the Sacred heart at Notre Dame...   \n",
      "3                  What is the Grotto at Notre Dame?   \n",
      "4  What sits on top of the Main Building at Notre...   \n",
      "\n",
      "                                    answer  \n",
      "0               Saint Bernadette Soubirous  \n",
      "1                a copper statue of Christ  \n",
      "2                        the Main Building  \n",
      "3  a Marian place of prayer and reflection  \n",
      "4       a golden statue of the Virgin Mary  \n",
      "(87598, 3)\n"
     ]
    }
   ],
   "source": [
    "#Predict on SQUAD\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "predictor = SimpleSeq2SeqPredictor(model_pred, dataset_reader=reader)\n",
    "\n",
    "squad = pd.read_csv('/home/infili/translation/Translation/SQUAD/squad_train_1.1.csv', sep='\\t') \n",
    "squad = squad.drop(squad.index[75207])\n",
    "\n",
    "\n",
    "print(squad.head())\n",
    "print(squad.shape)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#print(squad.iloc[0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87598/87598 [14:55:47<00:00,  1.63it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Create the pandas DataFrame of the translated SQuAD\n",
    "squad_el = pd.DataFrame(columns = [ 'context', 'question', 'answer']) \n",
    "\n",
    "text_el = []\n",
    "questions_el = []\n",
    "answers_el = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(0,len(squad))):\n",
    "    text = sent_tokenize(squad.iloc[i,0])\n",
    "    question = squad.iloc[i,1]\n",
    "    answer = squad.iloc[i,2]\n",
    "\n",
    "#Parsing the output to remove quotes and irrelevant characters\n",
    "\n",
    "    import re\n",
    "    regex = r\"', '\"\n",
    "    regex2 = r\", \\\"'\\\", '\"\n",
    "    subst = \"\"\n",
    "    subst2 = \"\"\n",
    "    translated1 = []\n",
    "\n",
    "# Iterative translation of the original SQuAD:\n",
    "    for j in text:\n",
    "        p = predictor.predict(j)['predicted_tokens']\n",
    "        result1 = re.sub(regex, subst, str(p), 0, re.MULTILINE | re.IGNORECASE)\n",
    "        result1 = re.sub(regex2, subst2, str(result1), 0, re.MULTILINE | re.IGNORECASE)\n",
    "        translated1.append(result1)\n",
    "        \n",
    "    text_el.append(' '.join(translated1))\n",
    "    \n",
    "    p2 = predictor.predict(question)['predicted_tokens']\n",
    "    result2 = re.sub(regex, subst, str(p2), 0, re.MULTILINE | re.IGNORECASE)\n",
    "    questions_el.append(re.sub(regex2, subst2, str(result2), 0, re.MULTILINE | re.IGNORECASE))\n",
    "        \n",
    "    p3 = predictor.predict(answer)['predicted_tokens']\n",
    "    result3 = re.sub(regex, subst, str(p3), 0, re.MULTILINE | re.IGNORECASE)\n",
    "    answers_el.append(re.sub(regex2, subst2, str(result3), 0, re.MULTILINE | re.IGNORECASE))\n",
    "        \n",
    "    \n",
    "squad_el['context'] = text_el\n",
    "squad_el['question'] = questions_el\n",
    "squad_el['answer'] = answers_el\n",
    "squad_el.head(10)\n",
    "\n",
    "#Save to CSV\n",
    "squad_el.to_csv('~/translation/Translation/SQUAD/squad_train_1.1_el_XXX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
